import hashlib
import json
import os
import time
from typing import Any, Dict, List

from crewai import LLM, Agent
from openai import OpenAI

# ---- å°ˆæ¡ˆæ¨¡çµ„ï¼ˆæ³¨æ„ç›¸å°åŒ¯å…¥ï¼‰----
from ..embedding import safe_to_vector
from ..toolkits.memory_store import retrieve_memory_pack_v3, upsert_atoms_and_surfaces

# redis èˆ‡å·¥å…·ï¼šæ³¨æ„ summarize_chunk_and_commit ä¾†è‡ª tools.py
from ..toolkits.redis_store import (
    fetch_all_history,
    get_summary,
    peek_remaining,
    purge_user_session,
    set_state_if,
)
from ..toolkits.tools import (
    AlertCaseManagerTool,
    ModelGuardrailTool,
    SearchMilvusTool,
    summarize_chunk_and_commit,
)

OPENAI_MODEL = os.getenv("MODEL_NAME", "gpt-4o-mini")
EMBED_DIM = int(os.getenv("EMBED_DIM", 1536))

granddaughter_llm = LLM(
    model=os.getenv("MODEL_NAME", "gpt-4o-mini"),
    temperature=0.5,
)

guard_llm = LLM(
    model=os.getenv("MODEL_NAME", "gpt-4o-mini"),
    temperature=0,
)


# ========= å°å·¥å…· =========
def _now_ms() -> int:
    return int(time.time() * 1000)


def _stable_group_key(display_text: str) -> str:
    # ä»¥å±•ç¤ºæ–‡æœ¬ï¼ˆatom çš„å¯è®€æ•˜è¿°ï¼‰ç‚ºåŸºæº–åš hashï¼Œç¢ºä¿ atom/surface ç”¨åŒä¸€æŠŠ gk
    h = hashlib.sha1(display_text.lower().encode("utf-8")).hexdigest()[:32]
    return "auto:" + h


def _render_session_transcript(user_id: str, k: int = 9999) -> str:
    rounds = fetch_all_history(user_id) or []
    out = []
    for i, r in enumerate(rounds[-k:], 1):
        q = (r.get("input") or "").strip()
        a = (r.get("output") or "").strip()
        out.append(f"{i:02d}. ä½¿ç”¨è€…ï¼š{q}")
        out.append(f"    åŠ©æ‰‹ï¼š{a}")
    return "\n".join(out)


# ========= Finalizeï¼šè¨˜æ†¶è’¸é¤¾ =========
_DISTILL_SYS = """
ä½ æ˜¯ã€Œè¨˜æ†¶è’¸é¤¾å™¨ã€ã€‚è«‹å¾æœ¬è¼ªå°è©±ä¸­ï¼ŒåªæŠ½å–ã€å¯é•·æœŸé‡ç”¨çš„æ—¢å®šäº‹å¯¦ã€ï¼Œä¸¦ç‚ºæ¯ä¸€é …æŒ‡å®šä¿å­˜æœŸé™ï¼ˆTTLï¼‰ã€‚
æŠ½å–è¦å‰‡ï¼ˆå‹™å¿…éµå®ˆï¼‰ï¼š
- åªæ”¶ï¼šéæ•å²ã€å›ºå®šåå¥½ã€é†«å›‘/ç”¨è—¥ï¼ˆç¾è¡Œï¼‰ã€å›ºå®šè¡Œç¨‹/æé†’ã€è¯çµ¡äººã€æ…¢æ€§ç—…å²ã€é•·æœŸé™åˆ¶/ç¦å¿Œã€‚
- ä¸æ”¶ï¼šå¯’æš„ã€ä¸€æ¬¡æ€§äº‹ä»¶ã€çŸ­æœŸç—‡ç‹€ã€çŒœæ¸¬ã€æ¨¡å‹æ„è¦‹ã€‚
- æ¯é …æä¾› 60â€“160 å­—å¯è®€æ•˜è¿°ï¼ˆdisplay_textï¼‰ï¼Œä¸å¾—æ·»åŠ æœªå‡ºç¾çš„æ¨æ¸¬ã€‚
- æ¯é …é™„ 1â€“3 å¥ã€evidence åŸè©±ã€‘ï¼ˆé€å­—å¼•ç”¨ä½¿ç”¨è€…æˆ–åŠ©æ‰‹è©±èªï¼‰ï¼Œä¹‹å¾Œå°‡ä»¥æ­¤åšå‘é‡æª¢ç´¢ã€‚
- TTL è¦å‰‡ï¼š
  allergy/æ…¢æ€§ç—…/è¯çµ¡äººï¼šttl_days=0ï¼ˆæ°¸ä¹…ï¼‰
  é†«å›‘/ç”¨è—¥ï¼šttl_days=180
  å›ºå®šåå¥½ï¼šttl_days=365
  å›ºå®šè¡Œç¨‹/æé†’ï¼šttl_days=90
  å…¶ä»–é•·æœŸé™åˆ¶/ç¦å¿Œï¼šttl_days=365
- è‹¥ç„¡ç¬¦åˆï¼Œè¼¸å‡ºç©ºé™£åˆ— []ã€‚
è¼¸å‡º JSON é™£åˆ—ï¼Œå…ƒç´ æ ¼å¼ï¼š
{
  "type": "allergy|preference|doctor_order|schedule|reminder|contact|condition|constraint|note",
  "display_text": "<60-160å­—å¯è®€æ•˜è¿°>",
  "evidence": ["<åŸè©±1>", "<åŸè©±2>"],  // æœ€å¤š3å¥
  "ttl_days": 0|90|180|365
}
""".strip()


def _distill_facts(user_id: str) -> List[Dict[str, Any]]:
    transcript = _render_session_transcript(user_id)
    if not transcript.strip():
        return []
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    res = client.chat.completions.create(
        model=OPENAI_MODEL,
        temperature=0.2,
        max_tokens=900,
        messages=[
            {"role": "system", "content": _DISTILL_SYS},
            {
                "role": "user",
                "content": f"ä½¿ç”¨è€…æœ¬è¼ªå°è©±å¦‚ä¸‹ï¼ˆé€å­—ï¼‰ï¼š\n<<<\n{transcript}\n>>>",
            },
        ],
    )
    raw = (res.choices[0].message.content or "").strip()
    # æ¸…æ‰ ```json å€å¡Šç¬¦è™Ÿ
    if raw.startswith("```"):
        lines = [ln for ln in raw.splitlines() if not ln.strip().startswith("```")]
        raw = "\n".join(lines).strip()
    lb, rb = raw.find("["), raw.rfind("]")
    if lb == -1 or rb == -1 or rb <= lb:
        return []
    try:
        arr = json.loads(raw[lb : rb + 1])
        return arr if isinstance(arr, list) else [arr]
    except Exception:
        return []


def _ttl_days_to_expire_at(ttl_days: int) -> int:
    if not ttl_days or int(ttl_days) == 0:
        return 0
    return _now_ms() + int(ttl_days) * 86400 * 1000


def finalize_session(user_id: str) -> None:
    """
    æœƒè©±æ”¶å°¾ï¼š
    1) ï¼ˆå¯é¸ï¼‰è£œæ‘˜è¦ï¼ˆç´”ç‚ºé™æœ¬ï¼Œä¸å½±éŸ¿ LTMï¼‰
    2) LLM è’¸é¤¾ â†’ æ—¢å®šäº‹å¯¦ + evidence(åŸè©±) + ttl_days
    3) å¯«å…¥ Milvusï¼š
       - atomï¼štext=display_textï¼›embedding=0 å‘é‡ï¼›expire_at=ç”± ttl_days æ±ºå®š
       - surfaceï¼štext=åŸè©±ï¼›embedding=E(åŸè©±)ï¼›expire_at åŒä¸Š
    4) æ¸…ç† Redis session
    """
    # 1) æ‘˜è¦ï¼ˆå¯è¨»è§£æ‰ï¼‰
    try:
        set_state_if(user_id, expect="ACTIVE", to="FINALIZING")
        start, remaining = peek_remaining(user_id)
        if remaining:
            summarize_chunk_and_commit(
                user_id, start_round=start, history_chunk=remaining
            )
    except Exception as e:
        print(f"[finalize summary warn] {e}")

    # 2) è¨˜æ†¶è’¸é¤¾
    facts = _distill_facts(user_id)

    # 3) å…¥åº«
    to_upsert = []
    session_id = f"sess:{int(time.time())}"
    for f in facts:
        display = (f.get("display_text") or "").strip()
        if not display:
            continue
        ttl_days = int(f.get("ttl_days", 365))
        expire_at = _ttl_days_to_expire_at(ttl_days)
        gk = _stable_group_key(display)  # â˜… ç”¢ç”Ÿç©©å®š group_key

        # atomï¼ˆå±•ç¤ºç”¨ï¼‰
        to_upsert.append(
            {
                "type": "atom",
                "group_key": gk,
                "text": display[:4000],
                "importance": (
                    4
                    if f.get("type")
                    in ("allergy", "doctor_order", "contact", "condition")
                    else 3
                ),
                "confidence": 0.9,
                "times_seen": 1,
                "status": "active",
                "source_session_id": session_id,
                "expire_at": expire_at,
                "embedding": [0.0] * EMBED_DIM,  # å ä½ï¼Œä¸åƒèˆ‡æª¢ç´¢
            }
        )

        # surfacesï¼ˆæª¢ç´¢ä¸»åŠ›ï¼‰ï¼šå° evidence åŸå¥åš embedding
        for ev in (f.get("evidence") or [])[:3]:
            ev_txt = (ev or "").strip()
            if not ev_txt:
                continue
            vec = safe_to_vector(ev_txt) or []
            if not vec:
                continue
            to_upsert.append(
                {
                    "type": "surface",
                    "group_key": gk,
                    "text": ev_txt[:4000],
                    "importance": 2,
                    "confidence": 0.95,
                    "times_seen": 1,
                    "status": "active",
                    "source_session_id": session_id,
                    "expire_at": expire_at,
                    "embedding": vec,
                }
            )

    if to_upsert:
        try:
            upsert_atoms_and_surfaces(user_id, to_upsert)
            print(f"âœ… finalizeï¼šå·²å¯«å…¥é•·æœŸè¨˜æ†¶ {len(to_upsert)} ç­†ï¼ˆatom/surfaceï¼‰")
        except Exception as e:
            print(f"[finalize upsert error] {e}")
    else:
        print("â„¹ï¸ finalizeï¼šæœ¬è¼ªæ²’æœ‰å¯é•·æœŸä¿å­˜çš„äº‹å¯¦")

    # 4) æ¸…ç† session
    try:
        purge_user_session(user_id)
    except Exception as e:
        print(f"[finalize purge warn] {e}")


# ========= æª¢ç´¢æ¥é» =========
def build_prompt_from_redis(user_id: str, k: int = 6, current_input: str = "") -> str:
    parts: List[str] = []

    # (1) é•·æœŸè¨˜æ†¶ï¼ˆåŸè©±å°å‘ï¼‰
    if current_input:
        qv = safe_to_vector(current_input)
        if qv:
            try:
                mem_pack = retrieve_memory_pack_v3(
                    user_id=user_id,
                    query_vec=qv,
                    topk_groups=5,
                    sim_thr=0.5,
                    tau_days=45,
                    include_raw_qa=False,
                )
                if mem_pack:
                    parts.append(mem_pack)
            except Exception as e:
                print(f"[memory v3 retrieval warn] {e}")

    # (2) æ­·å²æ‘˜è¦ï¼ˆå¯é¸ï¼‰
    try:
        summary_text, _ = get_summary(user_id)
        if summary_text:
            parts.append("ğŸ“Œ æ­·å²æ‘˜è¦ï¼š\n" + summary_text.strip())
    except Exception:
        pass

    # (3) è¿‘æœŸæœªæ‘˜è¦ç‰‡æ®µï¼ˆå¯é¸ï¼‰
    try:
        rounds = fetch_all_history(user_id) or []
        tail = rounds[-k:]
        if tail:
            lines = []
            for r in tail:
                q = (r.get("input") or "").strip()
                a = (r.get("output") or "").strip()
                lines.append(f"ä½¿ç”¨è€…ï¼š{q}")
                lines.append(f"åŠ©æ‰‹ï¼š{a}")
            parts.append("ğŸ•“ è¿‘æœŸå°è©±ï¼ˆæœªæ‘˜è¦ï¼‰ï¼š\n" + "\n".join(lines))
    except Exception:
        pass

    return "\n\n".join([p for p in parts if p.strip()]) or ""


# ========= CrewAI ä»£ç†å·¥å» ï¼ˆä¾› chat_pipeline åŒ¯å…¥ï¼‰=========
def create_guardrail_agent() -> Agent:
    return Agent(
        role="Guardrail",
        goal="åˆ¤æ–·æ˜¯å¦éœ€è¦æ””æˆªä½¿ç”¨è€…è¼¸å…¥ï¼ˆå®‰å…¨/æ³•å¾‹/é†«ç™‚ç­‰é«˜é¢¨éšªï¼‰",
        backstory="åš´è¬¹çš„å®‰å…¨å¯©æŸ¥å™¨",
        tools=[ModelGuardrailTool()],
        verbose=False,
        allow_delegation=False,
        llm=guard_llm,
        memory=False,
    )


def create_health_companion(user_id: str) -> Agent:
    return Agent(
        role="National Granddaughter Ally",
        goal="æº«æš–é™ªä¼´ä¸¦çµ¦ä¸€è¡Œå›è¦†ï¼›å·¥å…·åƒ…åœ¨ç¬¦åˆç•¶è¼ªè¦å‰‡æ™‚ä½¿ç”¨ï¼Œé¿å…ä¸å¿…è¦çš„æŸ¥è©¢èˆ‡é€šå ±ã€‚",
        backstory=f"é™ªä¼´ä½¿ç”¨è€… {user_id} çš„æº«æš–å­«å¥³",
        tools=[
            SearchMilvusTool(),
            AlertCaseManagerTool(),
        ],  # ç·Šæ€¥æ™‚æœƒè¢«ä»»å‹™ prompt è¦æ±‚è§¸ç™¼
        verbose=False,
        allow_delegation=False,
        llm=granddaughter_llm,
        memory=False,
        max_iterations=1,
    )
    
